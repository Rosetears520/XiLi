# 数据处理总结文档

> 本文档为数据分析工具箱的项目级总结模板，记录每次数据处理运行的环境、输入、处理步骤、结果、异常与可复现性信息。

---

## 1. 环境 (Environment)

| 项目 | 版本/配置 |
|------|----------|
| Python 版本 | 3.12.8 |
| 包管理工具 | uv + .venv |
| 运行命令 | `uv run -- python <script.py> [args...]` |

### 关键依赖

| 包名 | 版本 | 用途 |
|------|------|------|
| gradio | >=4.19.0 | Web GUI 框架 |
| pandas | >=2.0.0 | 数据处理 |
| numpy | >=1.24.0 | 数值计算 |
| scipy | >=1.10.0 | 科学计算 |
| scikit-learn | >=1.2.0 | 机器学习（K-means 等） |
| matplotlib | >=3.5.0 | 绘图 |
| seaborn | >=0.12.0 | 统计可视化 |
| openpyxl | >=3.1.0 | Excel 文件读写 |
| jieba | >=0.42.0 | 中文分词 |
| wordcloud | >=1.9.0 | 词云生成 |
| gensim | >=4.3.0 | LDA 主题模型 |
| pyLDAvis | >=3.4.0 | LDA 可视化 |
| snownlp | >=0.12.3 | 中文情感分析 |
| pillow | >=10.0.0 | 图像处理 |
| tqdm | >=4.66.0 | 进度条 |

---

## 2. 输入 (Input)

### 2.1 工具输入要求

#### 核心分析工具

| 工具名称 | 输入格式 | 必需列/参数 | 说明 |
|----------|----------|-------------|------|
| 熵权 TOPSIS | CSV/Excel (.csv/.xlsx) | 数据列、可选：分组列(group_cols)、年份列(year_col)、ID列(id_cols)、负向指标(negative_indicators) | 支持多列分组、年份分组等多种模式 |
| 秩和检验 | CSV/Excel (.csv/.xlsx) | 数据列、题目列(question_cols) 或 分组列(group_cols)、因变量列(dv_col) | 支持 questions 和 group 两种模式 |

#### 可视化/图像工具

| 工具名称 | 输入格式 | 必需列/参数 | 说明 |
|----------|----------|-------------|------|
| 词云图 | 文本文件 (.txt) | 词频格式：每行 "词 频数" | 可选：遮罩图片、字体、颜色方案 |
| 黑白图片 | 图像文件 (.png/.jpg/.jpeg等) | 像素阈值 (0-255) | 将图片转换为黑白二值图像 |

#### 描述统计/填补工具

| 工具名称 | 输入格式 | 必需列/参数 | 说明 |
|----------|----------|-------------|------|
| 计算年份平均值 | CSV/Excel (.csv/.xlsx) | 列名列表 (cols)、可选：重命名对 | 按股票代码等计算指定列的平均值 |
| 平均增长率 | CSV/Excel (.csv/.xlsx) | 数据列、省份列 | 按省份分组，使用年均增长率填充缺失值 |

#### 聚类分析工具

| 工具名称 | 输入格式 | 必需列/参数 | 说明 |
|----------|----------|-------------|------|
| K-means | CSV/Excel (.csv/.xlsx) | 数值数据列 | 自动确定最佳聚类数并生成可视化结果 |

#### 主题模型/NLP 工具

| 工具名称 | 输入格式 | 必需列/参数 | 说明 |
|----------|----------|-------------|------|
| LDA模型 | 分词文本文件 (.txt) | 分词后的文本（每行一个文档） | 生成主题词云和可视化结果 |
| LDA困惑度和一致性 | 分词文本文件 (.txt) | 分词后的文本、主题数范围 | 评估不同主题数的 LDA 模型 |
| SnowNLP训练 | 正面/负面语料文件 (.txt) | 正面语料、负面语料 | 训练情感分析模型 |
| SnowNLP情感分析 | CSV/Excel (.csv/.xlsx) + 模型文件 | 模型路径、数据列 | 对 CSV/Excel 数据进行情感分析并生成分布图表 |

### 2.2 本次运行输入

> 运行时请填写以下内容：

- **运行时间**: `YYYY-MM-DD HH:MM:SS`
- **运行目录**: `runs/<timestamp>_<uuid>/`
- **使用的工具**: `<工具名称>`

**输入文件列表**:
| 文件名 | 路径 | 格式 | 说明 |
|--------|------|------|------|
| | | | |

**命令行参数**:
```bash
<完整命令>
```

---

## 3. 处理步骤 (Processing Steps)

### 3.1 工具处理流程

#### 熵权 TOPSIS
1. 读取 Excel 数据文件
2. 数据预处理（处理缺失值、异常值）
3. 标准化处理（应用 `eps_shift` 非负平移常数）
4. 计算熵权
5. 应用 TOPSIS 方法计算贴近度
6. （可选）按分组列进行分组计算
7. 输出结果到 Excel 文件

#### 秩和检验
1. 读取 Excel 数据文件
2. 按模式（questions/group）分组数据
3. 执行非参数检验（Mann-Whitney U 或 Kruskal-Wallis H）
4. 计算统计量和 p 值
5. 根据显著性水平判断差异显著性
6. 输出结果到 Excel 文件

#### 词云图
1. 读取词频文本文件
2. 解析词和频数
3. （可选）加载遮罩图片
4. （可选）设置字体和颜色方案
5. 生成词云图像
6. 保存到指定路径

#### 黑白图片
1. 读取输入图片
2. 转换为灰度图像
3. 应用阈值进行二值化
4. 保存输出图片

#### 计算年份平均值
1. 读取 Excel 数据文件
2. 按股票代码等分组
3. 计算指定列的平均值
4. （可选）列重命名
5. 输出到 Excel 文件

#### 平均增长率
1. 读取 CSV 数据文件
2. 按省份分组
3. 计算年均增长率
4. 使用增长率填充缺失值
5. 输出到 CSV 文件

#### K-means 聚类
1. 读取 Excel 数据文件
2. 数据标准化
3. 尝试不同 K 值（2 到 max_k）
4. 计算聚类评估指标（轮廓系数、Calinski-Harabasz 指数、Davies-Bouldin 指数）
5. 选择最佳 K 值
6. 执行最终聚类
7. 输出聚类结果和可视化图表

#### LDA 模型
1. 读取分词文本文件
2. 构建词典和语料库
3. 过滤低频词和高频词（no_below, no_above）
4. 训练 LDA 主题模型
5. 计算一致性指标
6. 生成主题词云
7. 保存模型和可视化结果

#### LDA 困惑度和一致性
1. 读取分词文本文件
2. 构建词典和语料库
3. 对主题数范围内的每个 K 值：
   - 训练 LDA 模型
   - 计算困惑度（Perplexity）
   - 计算一致性（Coherence）
4. 绘制曲线图
5. 输出到 Excel 文件和图片

#### SnowNLP 训练
1. 读取正面和负面语料
2. 训练 SnowNLP 情感分析模型
3. 保存模型文件

#### SnowNLP 情感分析
1. 加载训练好的模型
2. 读取 Excel 数据文件
3. 对指定列进行情感分析
4. 计算情感分数
5. 生成分布直方图
6. 输出到 Excel 文件和图表

### 3.2 本次运行处理步骤

> 运行时记录具体处理步骤：

1. ...
2. ...
3. ...

---

## 4. 结果 (Output)

### 4.1 工具输出文件

| 工具名称 | 输出文件类型 | 默认文件名/路径 | 说明 |
|----------|--------------|-----------------|------|
| 熵权 TOPSIS | Excel (.xlsx) | `entropy_topsis.xlsx` | 包含熵权、标准化值、贴近度等 |
| 秩和检验 | Excel (.xlsx) | `rank_tests.xlsx` | 包含统计量、p值、显著性结果 |
| 词云图 | 图像 (.png/.jpg) | `wordcloud.png` | 词云可视化图像 |
| 黑白图片 | 图像 (.png/.jpg等) | `{stem}_binary.{suffix}` | 黑白二值图像 |
| 计算年份平均值 | Excel (.xlsx) | `yearly_averages.xlsx` | 各列的年份平均值 |
| 平均增长率 | CSV (.csv) | `average_growth_rate_result.csv` | 填充后的数据 |
| K-means | Excel + 图像 | `outputs/kmeans/` | 聚类结果、评估指标、可视化图表 |
| LDA模型 | 模型 + 图像 | `outputs/lda/` | LDA 模型文件、主题词云、可视化 |
| LDA困惑度和一致性 | Excel + 图像 | `lda_evaluation.xlsx`, `lda_evaluation.png` | 评估结果和曲线图 |
| SnowNLP训练 | 模型文件 | `sentiment.marshal` | 训练好的情感分析模型 |
| SnowNLP情感分析 | Excel + 图像 | `comments_with_sentiment.xlsx`, 分布图 | 带情感分数的数据和分布图 |

### 4.2 本次运行输出

| 文件名 | 类型 | 大小 | 路径 | 说明 |
|--------|------|------|------|------|
| | | | | |

**运行状态**:
- 返回码: `<0 表示成功>`
- 运行时间: `<秒>`
- 状态: `<成功/失败/部分失败>`

---

## 5. 异常/排错 (Exceptions & Troubleshooting)

### 5.1 常见错误与解决方案

| 错误类型 | 可能原因 | 解决方案 |
|----------|----------|----------|
| `FileNotFoundError` | 输入文件路径错误或文件不存在 | 检查文件路径是否正确，使用绝对路径 |
| `ValueError: could not convert string to float` | 数据列包含非数值内容 | 检查数据列是否全部为数值，清理异常值 |
| `ZeroDivisionError` | 数据全为零或无效 | 检查输入数据是否有效，添加数据验证 |
| `KeyError: 'xxx'` | 指定的列名不存在于输入文件中 | 检查列名是否正确（注意空格、大小写） |
| `UnicodeDecodeError` | 文件编码问题 | 确保使用 UTF-8 编码的文本文件 |
| `ImportError: No module named 'xxx'` | 缺少依赖包 | 运行 `uv pip install <package>` 安装依赖 |
| 图像不显示 | GUI 模式下 `plt.show()` 阻塞运行 | 使用 `--headless` 参数运行或修改代码禁用交互模式 |
| LDA 训练时间过长 | 文本数据量太大或主题数太多 | 减少 passes 或 topic_max，或增加 workers |
| 熵权计算出现 NaN | 数据包含 NaN 或 Inf | 先清理数据中的缺失值和异常值 |
| `eps_shift=0` 导致 log(0) | 标准化后出现零值 | 使用默认的 `eps_shift=0.01` 或确保数据为正 |

### 5.2 本次运行异常

> 如有异常，请记录：

**错误信息**:
```
<错误堆栈或消息>
```

**排查过程**:
1. ...
2. ...
3. ...

**解决方案**:
- ...

---

## 6. 日志与可复现性 (Logging & Reproducibility)

### 6.1 日志文件位置

每次运行都会在 `runs/<timestamp>_<uuid>/` 目录下生成以下文件：

- `run.log` - 运行日志，包含时间戳、命令行参数、返回码、stdout、stderr
- `inputs/` - 输入文件的副本
- 输出文件 - 具体文件名取决于工具

### 6.2 随机种子与确定性设置

为确保结果可复现，以下工具支持设置随机种子：

| 工具名称 | 随机种子参数 | 默认值 | 说明 |
|----------|--------------|--------|------|
| K-means | N/A | N/A | 使用 sklearn 的 `random_state=42`（硬编码） |
| LDA模型 | `--random-seed` | 42 | 可自定义，默认为 42 |
| LDA困惑度和一致性 | `--random-seed` | 42 | 可自定义，默认为 42 |

### 6.3 可复现性检查清单

在记录运行结果时，请确认：

- [ ] 记录完整的命令行参数
- [ ] 保存输入文件的副本
- [ ] 检查随机种子设置（如适用）
- [ ] 记录 Python 版本和依赖版本
- [ ] 保存运行日志文件
- [ ] 记录运行环境和操作系统

### 6.4 本次运行可复现性信息

- **随机种子**: `<工具支持的随机种子值>`
- **确定性设置**: `<其他影响结果确定性的设置>`

---

## 7. 运行历史 (Run History)

> 记录每次运行的基本信息，便于追溯。

| 日期 | 工具 | 输入文件 | 输出目录 | 状态 | 备注 |
|------|------|----------|----------|------|------|
| | | | | | |

---

## 8. 数据集处理政策

- Excel/CSV 原始导出和采集数据不得直接提交到仓库，非敏感示例应保留在 `tests/fixtures/` 或 docs/ 里。
- 每次运行的 `runs/<timestamp_uuid>/` 目录属于输出产物，应通过 .gitignore 忽略，方便自动化生成。
- 提交前确保 CSV/Excel 输入文件的敏感字段已脱敏或使用样本替代。

## 附录 A: 快速参考

### A.1 运行脚本

```bash
# 使用 uv 运行
uv run -- python <script.py> [args...]

# 运行测试
uv run -- pytest -q

# 启动 GUI
uv run -- python gradio_toolbox.py
```

### A.2 查看帮助

```bash
# 查看脚本帮助
uv run -- python <script.py> --help

# 查看统一 CLI 帮助
uv run -- python -m xili.cli topsis --help
uv run -- python -m xili.cli ranktest --help
```

---

**文档版本**: 1.0
**最后更新**: 2025-12-23
**维护者**: XiLiSuite 项目
